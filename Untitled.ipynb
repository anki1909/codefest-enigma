{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fun(x):\n",
    "    try:\n",
    "        x = x.split(',')\n",
    "    except:\n",
    "        x = []\n",
    "    len1 =len(x)\n",
    "    for i in range(0,7-len(x)):\n",
    "        x.append(1)\n",
    "    x.append(len1)    \n",
    "    return pd.Series(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train/train_submissions.csv')\n",
    "user_data = pd.read_csv('train/user_data.csv')\n",
    "problem_data = pd.read_csv('train/problem_data.csv')\n",
    "test = pd.read_csv('test_submissions_NeDLEvX.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "problem_data1 =problem_data['tags'].apply(fun)\n",
    "problem_data = pd.concat((problem_data,problem_data1),axis= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub= pd.read_csv('sample_submissions_wbscxqU.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index([u'user_id', u'problem_id', u'attempts_range'], dtype='object'),\n",
       " (155295, 3))"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns,train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index([u'user_id', u'submission_count', u'problem_solved', u'contribution',\n",
       "        u'country', u'follower_count', u'last_online_time_seconds',\n",
       "        u'max_rating', u'rating', u'rank', u'registration_time_seconds'],\n",
       "       dtype='object'), (3571, 11))"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_data.columns,user_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'problem_id', u'level_type', u'points', u'tags', 0, 1, 2, 3, 4, 5, 6,\n",
       "       7],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "problem_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'ID', u'user_id', u'problem_id'], dtype='object')"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = train.merge(user_data, on = 'user_id',how = 'left')\n",
    "train = train.merge(problem_data, on = 'problem_id',how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.merge(user_data, on = 'user_id',how = 'left')\n",
    "test = test.merge(problem_data, on = 'problem_id',how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "problem_id_count = train[['problem_id','attempts_range']].groupby('problem_id').agg('sum').reset_index()\n",
    "problem_id_count.columns = ['problem_id','problem_id_sum']\n",
    "train = train.merge(problem_id_count, on = 'problem_id',how = 'left')\n",
    "test = test.merge(problem_id_count, on = 'problem_id',how = 'left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = train.attempts_range\n",
    "ID = test.ID\n",
    "test = test.drop(['ID','tags'],axis =1)\n",
    "train = train.drop(['attempts_range','tags'],axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full = pd.concat((train,test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nuser_id_count = full[['user_id','problem_id']].groupby(['user_id']).apply(lambda x: np.unique(x)).reset_index()\\nuser_id_count.columns = ['user_id','problem_ids']\\nuser_solved = user_id_count.set_index('user_id')['problem_ids'].to_dict()\\ntotal_problem_ids = problem_data.problem_id.values\\n\\nfrom collections import  defaultdict\\nuser_not_solved = defaultdict()\\nfor i in user_solved.keys():\\n    user_not_solved[i] =  len(np.setdiff1d(total_problem_ids,user_solved[i])) * 1.0/6543\\nnot_solved = pd.DataFrame({'user_id':user_not_solved.keys(),'not_solved':user_not_solved.values()})\\n\\ntrain = train.merge(not_solved, on = ['user_id'],how = 'left')\\ntest = test.merge(not_solved, on = ['user_id'],how = 'left')\\n\""
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "user_id_count = full[['user_id','problem_id']].groupby(['user_id']).apply(lambda x: np.unique(x)).reset_index()\n",
    "user_id_count.columns = ['user_id','problem_ids']\n",
    "user_solved = user_id_count.set_index('user_id')['problem_ids'].to_dict()\n",
    "total_problem_ids = problem_data.problem_id.values\n",
    "\n",
    "from collections import  defaultdict\n",
    "user_not_solved = defaultdict()\n",
    "for i in user_solved.keys():\n",
    "    user_not_solved[i] =  len(np.setdiff1d(total_problem_ids,user_solved[i])) * 1.0/6543\n",
    "not_solved = pd.DataFrame({'user_id':user_not_solved.keys(),'not_solved':user_not_solved.values()})\n",
    "\n",
    "train = train.merge(not_solved, on = ['user_id'],how = 'left')\n",
    "test = test.merge(not_solved, on = ['user_id'],how = 'left')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "user_level_count = full[['user_id','level_type','submission_count']].groupby(['user_id','level_type']).agg('count').reset_index()\n",
    "user_level_count.columns = ['user_id','level_type','u_l_count']\n",
    "train = train.merge(user_level_count, on = ['user_id','level_type'],how = 'left')\n",
    "test = test.merge(user_level_count, on = ['user_id','level_type'],how = 'left')\n",
    "\n",
    "unique_level = full[['user_id','level_type']].groupby(['user_id']).apply(lambda x: len(np.unique(x))).reset_index()\n",
    "unique_level.columns = ['user_id','unique_level']\n",
    "train = train.merge(unique_level, on = ['user_id'],how = 'left')\n",
    "test = test.merge(unique_level, on = ['user_id'],how = 'left')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "user_id_count = full[['user_id','submission_count']].groupby('user_id').agg('count').reset_index()\n",
    "user_id_count.columns = ['user_id','user_id_count']\n",
    "train = train.merge(user_id_count, on = 'user_id',how = 'left')\n",
    "test = test.merge(user_id_count, on = 'user_id',how = 'left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "problem_id_count = full[['problem_id','submission_count']].groupby('problem_id').agg('count').reset_index()\n",
    "problem_id_count.columns = ['problem_id','problem_id_count']\n",
    "train = train.merge(problem_id_count, on = 'problem_id',how = 'left')\n",
    "test = test.merge(problem_id_count, on = 'problem_id',how = 'left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "user_id_count = full[['user_id','submission_count']].groupby('user_id').agg('sum').reset_index()\n",
    "user_id_count.columns = ['user_id','user_id_sum']\n",
    "train = train.merge(user_id_count, on = 'user_id',how = 'left')\n",
    "test = test.merge(user_id_count, on = 'user_id',how = 'left')\n",
    "\n",
    "\n",
    "problem_id_count = full[['problem_id','submission_count']].groupby('problem_id').agg('sum').reset_index()\n",
    "problem_id_count.columns = ['problem_id','problem_id_sum']\n",
    "train = train.merge(problem_id_count, on = 'problem_id',how = 'left')\n",
    "test = test.merge(problem_id_count, on = 'problem_id',how = 'left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn import preprocessing\n",
    "text_columns = []\n",
    "for f in train.columns:\n",
    "    if train[f].dtype== 'object':          \n",
    "        lbl = preprocessing.LabelEncoder()\n",
    "        lbl.fit(list(train[f].values) + list(test[f].values))\n",
    "        train[f] = lbl.transform(list(train[f].values))\n",
    "        test[f] = lbl.transform(list(test[f].values))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = train.replace(np.nan,-1)\n",
    "test = test.replace(np.nan,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "clf = GradientBoostingClassifier(max_depth=8,n_estimators=200,learning_rate=0.05)\n",
    "clf.fit(train,y)\n",
    "pred = clf.predict(test)\n",
    "pd.DataFrame({'ID':ID,'attempts_range':pred}).to_csv('sample_l.csv',index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "clf = GradientBoostingClassifier(max_depth=8)\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "predicted = cross_val_predict(clf, train, y, cv=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_score(y, predicted, average='weighted') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#0.48080644793437904"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "user_id_count = full[['user_id','problem_id','submission_count']].groupby(['user_id','problem_id']).agg('count').reset_index()\n",
    "#user_id_count.columns = ['user_id','user_id_count']\n",
    "#train = train.merge(user_id_count, on = 'user_id',how = 'left')\n",
    "#test = test.merge(user_id_count, on = 'user_id',how = 'left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id_count.submission_count.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'ID':ID,'attempts_range':pred})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "problem_id_count = full[['problem_id','country']].groupby('problem_id').agg('sum').reset_index()\n",
    "problem_id_count.columns = ['problem_id','problem_id_sum']\n",
    "train = train.merge(problem_id_count, on = 'problem_id',how = 'left')\n",
    "test = test.merge(problem_id_count, on = 'problem_id',how = 'left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id_count = full[['user_id','submission_count']].groupby('user_id').agg('sum').reset_index()\n",
    "user_id_count.columns = ['user_id','user_id_sum']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id_count.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_not_solved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
